---
title: "Deep learning in mlr"
author: "Jannek Thomas"
date: "13. 06 2018"
output:
  ioslides_presentation:
    css: txt_slides.css
    includes:
      in_header: header.html
    theme: united
    toc: yes
    widescreen: no
  beamer_presentation: default
  slidy_presentation: default
bibliography: lit.bibtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(reshape2)
library(ggplot2)
library(mlr)
library(mlrMBO)
library(mxnet)
source("../data/read_data.R")
```

## Software

* Packages required for this demo are mainly __mxnet, mlr__ and __mlrMBO__
* The learner for classification tasks with mxnet in mlr is still in development mode, thus include it via
```{R, echo = TRUE}
source("https://raw.githubusercontent.com/mlr-org/mlr-extralearner/master/R/RLearner_classif_mxff.R")
```
* Follow the instructions on [the mxnet page](https://mxnet.incubator.apache.org/install/index.html) for the installation


## Deep learning with mlr?

Yes:

* Methods for tuning, resampling, benchmarking and visualization are implemented within an unified framework
* Mxnet offers a performant interface which is directly executed in c++
* Parallelized, distributed GPU computation is also implemented

No:

* R implementations tend to be one step behind their python counterparts
* No stage loading methods such as the data generator available yet
* Specification of parameter settings is currently a little cumbersome


## Data: fashion MNIST

* Dataset offered by [Zalando](https://github.com/zalandoresearch/fashion-mnist)
* Consists of 70K images of 10 different fashion items such as pullovers, shirts, shoes...
* Images are grayscale and in format 28x28 as with [MNIST](http://yann.lecun.com/exdb/mnist/)
* Split in 60K (6K/ class) and 10K balanced test data

## Data: fashion MNIST

```{R, echo = FALSE, cache = FALSE, eval = TRUE, fig.cap = "Example data from fashion MNIST"}

train = load_image_file('../data/train-images-idx3-ubyte')
test = load_image_file('../data/t10k-images-idx3-ubyte')
train$y = load_label_file('../data/train-labels-idx1-ubyte')
test$y = load_label_file('../data/t10k-labels-idx1-ubyte')

data = as.data.frame(rbind(cbind(train$x, train$y), cbind(test$x, test$y)))
colnames(data) = c(colnames(data)[-785], "y")

# get data
showExamples(nExamplesClass = 10, randomize = TRUE)
```

## Simple CNN in mlr

```{R, echo = FALSE, eval = FALSE}
## Symbolic way
# set architecture as symbol
sym = mx.symbol.Variable("data")
sym = mx.symbol.Convolution(sym, kernel = c(3, 3), num_filter = 5)
sym = mx.symbol.Activation(sym, act_type = "tanh")
sym = mx.symbol.Pooling(sym, kernel = c(2, 2), stride = c(2, 2))
sym = mx.symbol.Flatten(sym)
sym = mx.symbol.FullyConnected(sym, num_hidden = 100)
sym = mx.symbol.Activation(sym, act_type = "tanh")
sym = mx.symbol.SoftmaxOutput(sym)

mx.model.FeedForward.create(symbol = sym, X = task_data, y = data$y,
  ctx = mx.cpu, num.round = 1, array.batch.size = 100, learning.rate = 0.05,
  eval.metric = mx.metric.accuracy, array.layout = "rowmajor")

# define the learner
lrn = makeLearner(cl = "classif.mxff",
  # architecture
  symbol = sym,
  verbose = TRUE,
  # bug: reshape is only triggered by conv.layer1=TRUE
  conv.layer1 = TRUE,
  conv.data.shape = c(28, 28),
  array.layout = "rowmajor",
  # training specs
  optimizer = "sgd",
  eval.metric = mx.metric.accuracy,
  validation.ratio = 0.2,
  # use ES
  epoch.end.callback = mx.callback.early.stop(bad.steps = 5, maximize = TRUE),
  # choose your weapon
  ctx = mx.cpu(6),
  # epochs
  num.round = 2,
  kvstore = "local"
)
```


```{R, echo = TRUE, eval = TRUE, message = FALSE}
# define the learner
lrn = makeLearner(cl = "classif.mxff",
  # architecture
  conv.layer1 = TRUE,
  conv.kernel1 = c(3, 3),
  act1 = "tanh",
  pool.kernel1 = c(2, 2),
  pool.stride1 = c(2, 2),
  num.layer2 = 100,
  act2 = "tanh",
  conv.data.shape = c(28, 28),
  # training specs
  optimizer = "sgd", num.round = 1,
  eval.metric = mx.metric.accuracy, validation.ratio = 0.2,
  epoch.end.callback = mx.callback.early.stop(bad.steps = 5, maximize = TRUE),
  ctx = mx.cpu(), # mx.gpu()
  kvstore = "local")
```


## Simple CNN in mlr

```{R, echo = TRUE, eval = TRUE, cache = FALSE, message = FALSE}
# define the task
task = makeClassifTask(id = "fmnist", data = data, target = "y")
# combine task and learner and train the model
set.seed(1337)
mod = train(learner = lrn, task = task, subset = c(1:60000))
# predict and measure
preds = predict(mod, task = task, subset = 60001:70000)
performance(pred = preds, measures = mmce)
```

## Simple CNN in mlr

```{R, echo = FALSE, out.width="100%", fig.align='center', fig.cap="Illustration of the simple mxnet's architecture", warning=FALSE, message=FALSE}
mxnet_model = mlr::getLearnerModel(mod)
graph.viz(symbol = mxnet_model$symbol, direction = "LR", graph.height.px = 150, type = "graph")
```


## Tuning the simple CNN

* There are several parameters in the architecture that we want to tune
* Set up the parameter space
```{R, echo = TRUE, eval = TRUE}
par.set = makeParamSet(
  makeNumericParam(id = "learning.rate", lower = 0.05, upper = 0.3),
  makeNumericParam(id = "momentum", lower = 0.7, upper = 0.99),
  makeIntegerParam(id = "num.layer2", lower = 10, 500),
  makeIntegerVectorParam(id = "conv.kernel1", lower = 2, upper = 5, len = 2),
  makeDiscreteParam(id = "act1", c("tanh", "relu", "sigmoid"))
)
```

## Tuning the simple CNN

* Tune the model with MBO
* possible budget constraints:
    * __iters:__ number of sequential optimization steps
    * __time.budget:__ time after which the search stops [sec]
    * __target.fun.value:__ search stops when this performance-value is reached

```{R, echo = TRUE, eval = FALSE, message = FALSE, cache = FALSE}
ctrl = makeMBOControl()
# set time budget in seconds
ctrl = setMBOControlTermination(ctrl, time.budget = 10)
tune.ctrl = makeTuneControlMBO(mbo.control = ctrl)
result = tuneParams(learner = lrn, task = task, resampling = cv3,
  par.set = par.set, control = tune.ctrl, show.info = TRUE)
print(as.data.frame(c(result$x, result$y)))
```

## Tuning the simple CNN

* Access the results and train model with the tuned parameter setting
```{R, echo = TRUE, eval = TRUE}
# set hyper parameters
lrn.tuned = setHyperPars(makeLearner(cl = "classif.mxff"), par.vals = result$x,
  conv.data.shape = c(28, 28))
mod.tuned = mlr::train(learner = lrn.tuned, task = task, subset = c(1:60000))
# predict and test performance
preds = predict(mod.tuned, task = task, subset = 60001:70000)
performance(pred = preds, measures = mmce)
```

## Fine-tune ResNet in mlr

* Use famous ResNet architecture
```{R, echo = FALSE}
source("https://raw.githubusercontent.com/apache/incubator-mxnet/master/example/image-classification/symbol_resnet-28-small.R")
resnet.sym = get_symbol()
graph.viz(symbol = resnet.sym, type = "graph")
```

## Fine-tune ResNet in mlr

* ResNet offers in total 76 hyperparameters such as:
```{R, echo = FALSE}
# create learner from mxnet symbol
lrn.resnet = makeLearner(cl = "classif.mxff", symbol = resnet.sym,
  conv.data.shape = c(28, 28), conv.layer1 = TRUE)
# print(length(lrn.resnet$par.set$pars))
print(lrn.resnet$par.set$pars[c(1, 5, 11)])
```


## Fine-tune ResNet in mlr

* Fine-tune some of them to our specific task
* Set parameter setting

```{R, echo = TRUE}
par.set = makeParamSet(
  makeNumericParam(id = "learning.rate", lower = 0.05, upper = 0.3),
  makeDiscreteParam(id = "optimizer", c("adam", "sgd", "rmsprop")),
  makeNumericParam(id = "beta1", lower = 0.8, upper = 0.95,
    # params can be dependent, e.g.: beta1 does only apply to "adam", see ?mx.opt.adam
    requires = quote(optimizer == "adam")),
  makeNumericParam(id = "gamma1", lower = 0.8, upper = 0.95,
    # vice versa to adam
    requires = quote(optimizer == "rmsprop")),
  makeIntegerParam(id = "num.layer1", lower = 10, 500),
  makeDiscreteParam(id = "act1", c("tanh", "relu", "sigmoid")),
  makeIntegerVectorParam(id = "conv.kernel3", lower = 1, upper = 5, len = 2)
)
```

## Fine-tune ResNet in mlr

```{R, echo = TRUE, eval = TRUE, message = FALSE, cache = FALSE}
ctrl = makeMBOControl()
# set max amount of optim iterations
ctrl = setMBOControlTermination(ctrl, iters = 5)
tune.ctrl = makeTuneControlMBO(mbo.control = ctrl)
result.resnet = tuneParams(learner = lrn.resnet, task = task, resampling = cv3,
  par.set = par.set, control = tune.ctrl, show.info = TRUE)
print(as.data.frame(c(result.resnet$x, result.resnet$y)))
```
